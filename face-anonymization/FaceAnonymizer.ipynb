{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zevu8_VmEY0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data_dir = 'processed_celeba_small/'\n",
        "\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import problem_unittests as tests\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import signal\n",
        "from contextlib import contextmanager\n",
        "import requests\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.nn import init\n",
        "#import helper\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def get_dataloader(batch_size, image_size, data_dir='processed_celeba_small/'):\n",
        "    \"\"\"\n",
        "    Batch the neural network data using DataLoader\n",
        "    :param batch_size: The size of each batch; the number of images in a batch\n",
        "    :param img_size: The square size of the image data (x, y)\n",
        "    :param data_dir: Directory where image data is located\n",
        "    :return: DataLoader with batched data\n",
        "    \"\"\"\n",
        "    \n",
        "    transform = transforms.Compose([transforms.Resize(image_size),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "    dataset = datasets.ImageFolder(data_dir, transform)\n",
        "\n",
        "    return DataLoader(dataset, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Define function hyperparameters\n",
        "batch_size = 128\n",
        "img_size = 32\n",
        "\n",
        "# Call your function and get a dataloader\n",
        "celeba_train_loader = get_dataloader(batch_size, img_size)\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(celeba_train_loader)\n",
        "images, _ = dataiter.next() # _ for no labels\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "plot_size=20\n",
        "for idx in np.arange(plot_size):\n",
        "    ax = fig.add_subplot(2, plot_size/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "\n",
        "def scale(x, feature_range=(-1, 1)):\n",
        "    ''' Scale takes in an image x and returns that image, scaled\n",
        "       with a feature_range of pixel values from -1 to 1. \n",
        "       This function assumes that the input x is already scaled from 0-1.'''\n",
        "    min, max = feature_range\n",
        "    \n",
        "    return x * (max - min) + min\n",
        "\n",
        "img = images[0]\n",
        "scaled_img = scale(img)\n",
        "\n",
        "print('Min: ', scaled_img.min())\n",
        "print('Max: ', scaled_img.max())\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(\n",
        "        in_channels, \n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        bias=False\n",
        "    )\n",
        "    \n",
        "    layers.append(conv_layer)\n",
        "    \n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "        \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, conv_dim):\n",
        "        \"\"\"\n",
        "        Initialize the Discriminator Module\n",
        "        :param conv_dim: The depth of the first convolutional layer\n",
        "        \"\"\"\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # complete init function\n",
        "        \n",
        "        # If conv_dim = 64\n",
        "        # 32 x 32 x 3\n",
        "        self.conv1 = conv(3, conv_dim, 4, batch_norm=False)\n",
        "        # 16 x 16 x 64\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        # 8 x 8 x 128\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        # 4 x 4 x 256\n",
        "        \n",
        "        self.fc = nn.Linear(conv_dim*4*4*4, 1)\n",
        "        # 1\n",
        "        \n",
        "        self.conv_dim = conv_dim\n",
        "        self.dropout = 0.2\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param x: The input to the neural network     \n",
        "        :return: Discriminator logits; the output of the neural network\n",
        "        \"\"\"\n",
        "        # define feedforward behavior\n",
        "        out = F.leaky_relu(self.conv1(x), self.dropout)\n",
        "        out = F.leaky_relu(self.conv2(out), self.dropout)\n",
        "        out = F.leaky_relu(self.conv3(out), self.dropout)\n",
        "        \n",
        "        # Flatten for FC layer\n",
        "        out = out.view(-1, self.conv_dim*4*4*4)\n",
        "        \n",
        "        return self.fc(out)\n",
        "\n",
        "tests.test_discriminator(Discriminator)\n",
        "\n",
        "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        bias=False\n",
        "    ))\n",
        "    \n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "        \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self, z_size, conv_dim):\n",
        "        \"\"\"\n",
        "        Initialize the Generator Module\n",
        "        :param z_size: The length of the input latent vector, z\n",
        "        :param conv_dim: The depth of the inputs to the *last* transpose convolutional layer\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # complete init function\n",
        "        # If conv_dim = 256\n",
        "        self.fc = nn.Linear(z_size, conv_dim*4*4*4)\n",
        "        # 16,384\n",
        "        \n",
        "        # Reshaped in forward to 1,024 x 4 x 4\n",
        "        self.deconv1 = deconv(conv_dim*4, conv_dim*2, 4)\n",
        "        # 512 x 4 x 4\n",
        "        self.deconv2 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        # 256 x 16 x 16\n",
        "        self.deconv3 = deconv(conv_dim, 3, 4)\n",
        "        # 3 x 32 x 32\n",
        "        \n",
        "        self.conv_dim = conv_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param x: The input to the neural network     \n",
        "        :return: A 32x32x3 Tensor image as output\n",
        "        \"\"\"\n",
        "        # define feedforward behavior\n",
        "        out = self.fc(x)\n",
        "        out = out.view(-1, self.conv_dim*4, 4, 4)\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out))\n",
        "        out = F.leaky_relu(self.deconv2(out))\n",
        "        out = F.tanh(self.deconv3(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "tests.test_generator(Generator)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    \"\"\"\n",
        "    Applies initial weights to certain layers in a model .\n",
        "    The weights are taken from a normal distribution \n",
        "    with mean = 0, std dev = 0.02.\n",
        "    :param m: A module or layer in a network    \n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    mean = 0.0\n",
        "    std_dev = 0.02\n",
        "    \n",
        "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "        init.normal_(m.weight.data, mean, std_dev)\n",
        "        \n",
        "        if hasattr(m, 'bias') and m.bias is not None:\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "def build_network(d_conv_dim, g_conv_dim, z_size):\n",
        "    # define discriminator and generator\n",
        "    D = Discriminator(d_conv_dim)\n",
        "    G = Generator(z_size=z_size, conv_dim=g_conv_dim)\n",
        "\n",
        "    # initialize model weights\n",
        "    D.apply(weights_init_normal)\n",
        "    G.apply(weights_init_normal)\n",
        "\n",
        "    print(D)\n",
        "    print()\n",
        "    print(G)\n",
        "    \n",
        "    return D, G\n",
        "\n",
        "# Define model hyperparams\n",
        "d_conv_dim = 64\n",
        "g_conv_dim = 256\n",
        "z_size = 128\n",
        "\n",
        "D, G = build_network(d_conv_dim, g_conv_dim, z_size)\n",
        "\n",
        "# Check for a GPU\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Training on GPU!')\n",
        "\n",
        "    '''Calculates how close discriminator outputs are to being real.\n",
        "       param, D_out: discriminator logits\n",
        "       return: real loss'''\n",
        "    batch_size = D_out.size(0)\n",
        "    \n",
        "    if smooth:\n",
        "        labels = torch.ones(batch_size) * 0.9\n",
        "    else:\n",
        "        labels = torch.ones(batch_size)\n",
        "    \n",
        "    if train_on_gpu:\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def fake_loss(D_out):\n",
        "    '''Calculates how close discriminator outputs are to being fake.\n",
        "       param, D_out: discriminator logits\n",
        "       return: fake loss'''\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.zeros(batch_size)\n",
        "    \n",
        "    if train_on_gpu:\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "# Create optimizers for the discriminator D and generator G\n",
        "lr = .0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "\n",
        "d_optimizer = optim.Adam(D.parameters(), lr, [beta1, beta2])\n",
        "g_optimizer = optim.Adam(G.parameters(), lr, [beta1, beta2])\n",
        "\n",
        "def train(D, G, n_epochs, print_every=50):\n",
        "    '''\n",
        "       param, D: the discriminator network\n",
        "       param, G: the generator network\n",
        "       param, n_epochs: number of epochs to train for\n",
        "       param, print_every: when to print and record the models' losses\n",
        "       return: D and G losses'''\n",
        "    \n",
        "    # move models to GPU\n",
        "    if train_on_gpu:\n",
        "        D.cuda()\n",
        "        G.cuda()\n",
        "\n",
        "    # keep track of loss and generated, \"fake\" samples\n",
        "    samples = []\n",
        "    losses = []\n",
        "\n",
        "    # Get some fixed data for sampling.\n",
        "    sample_size=16\n",
        "    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "    fixed_z = torch.from_numpy(fixed_z).float()\n",
        "    # move z to GPU if available\n",
        "    if train_on_gpu:\n",
        "        fixed_z = fixed_z.cuda()\n",
        "\n",
        "    # epoch training loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # batch training loop\n",
        "        for batch_i, (real_images, _) in enumerate(celeba_train_loader):\n",
        "\n",
        "            batch_size = real_images.size(0)\n",
        "            real_images = scale(real_images)\n",
        "            \n",
        "            # 1. Train the discriminator on real and fake images\n",
        "            d_optimizer.zero_grad()\n",
        "            \n",
        "            if train_on_gpu:\n",
        "                real_images = real_images.cuda()\n",
        "                \n",
        "            D_real = D(real_images)\n",
        "            d_real_loss = real_loss(D_real, smooth=True)\n",
        "            \n",
        "            z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "            z = torch.from_numpy(z).float()\n",
        "            \n",
        "            if train_on_gpu:\n",
        "                z = z.cuda()\n",
        "                \n",
        "            fake_images = G(z)\n",
        "            \n",
        "            D_fake = D(fake_images)\n",
        "            d_fake_loss = fake_loss(D_fake)\n",
        "            \n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "            \n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # 2. Train the generator with an adversarial loss\n",
        "            g_optimizer.zero_grad()\n",
        "            \n",
        "            z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "            z = torch.from_numpy(z).float()\n",
        "            \n",
        "            if train_on_gpu:\n",
        "                z = z.cuda()\n",
        "                \n",
        "            fake_images = G(z)\n",
        "            \n",
        "            D_fake = D(fake_images)\n",
        "            g_loss = real_loss(D_fake)\n",
        "            \n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            # Print some loss stats\n",
        "            if batch_i % print_every == 0:\n",
        "                # append discriminator loss and generator loss\n",
        "                losses.append((d_loss.item(), g_loss.item()))\n",
        "                # print discriminator and generator loss\n",
        "                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                        epoch+1, n_epochs, d_loss.item(), g_loss.item()))\n",
        "\n",
        "\n",
        "        ## AFTER EACH EPOCH##    \n",
        "        G.eval() # for generating samples\n",
        "        samples_z = G(fixed_z)\n",
        "        samples.append(samples_z)\n",
        "        G.train() # back to training mode\n",
        "\n",
        "    # Save training generator samples\n",
        "    with open('train_samples.pkl', 'wb') as f:\n",
        "        pkl.dump(samples, f)\n",
        "    \n",
        "    # finally return losses\n",
        "    return losses\n",
        "\n",
        "DELAY = INTERVAL = 4 * 60  # interval time in seconds\n",
        "MIN_DELAY = MIN_INTERVAL = 2 * 60\n",
        "KEEPALIVE_URL = \"https://nebula.udacity.com/api/v1/remote/keep-alive\"\n",
        "TOKEN_URL = \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\"\n",
        "TOKEN_HEADERS = {\"Metadata-Flavor\":\"Google\"}\n",
        "\n",
        "def _request_handler(headers):\n",
        "    def _handler(signum, frame):\n",
        "        requests.request(\"POST\", KEEPALIVE_URL, headers=headers)\n",
        "    return _handler\n",
        "\n",
        "@contextmanager\n",
        "def active_session(delay=DELAY, interval=INTERVAL):\n",
        "    token = requests.request(\"GET\", TOKEN_URL, headers=TOKEN_HEADERS).text\n",
        "    headers = {'Authorization': \"STAR \" + token}\n",
        "    delay = max(delay, MIN_DELAY)\n",
        "    interval = max(interval, MIN_INTERVAL)\n",
        "    original_handler = signal.getsignal(signal.SIGALRM)\n",
        "    try:\n",
        "        signal.signal(signal.SIGALRM, _request_handler(headers))\n",
        "        signal.setitimer(signal.ITIMER_REAL, delay, interval)\n",
        "        yield\n",
        "    finally:\n",
        "        signal.signal(signal.SIGALRM, original_handler)\n",
        "        signal.setitimer(signal.ITIMER_REAL, 0)\n",
        "\n",
        "n_epochs = 50\n",
        "# call training function\n",
        "with active_session():\n",
        "    losses = train(D, G, n_epochs=n_epochs)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
        "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()\n",
        "\n",
        "# helper function for viewing a list of passed in sample images\n",
        "def view_samples(epoch, samples):\n",
        "    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n",
        "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
        "        img = img.detach().cpu().numpy()\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        img = ((img + 1)*255 / (2)).astype(np.uint8)\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "        im = ax.imshow(img.reshape((32,32,3)))\n",
        "\n",
        "# Load samples from generator, taken while training\n",
        "with open('train_samples.pkl', 'rb') as f:\n",
        "    samples = pkl.load(f)\n",
        "\n",
        "_ = view_samples(-1, samples)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}